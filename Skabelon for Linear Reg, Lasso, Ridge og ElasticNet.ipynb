{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('Boliga - Final for training.csv')\n",
    "df = df.drop(columns = ['Kommune', 'lotSize', 'Relativ Ledighed', 'Total_reported',\n",
    "                        'Socioeconomic_index', 'expenses_per_school_student',\n",
    "                       'expenses_sport_and_other_cultural_activities', 'forest_distance',\n",
    "                       'coast_distance', 'isForeclosure', 'Ejerudgift'])\n",
    "\n",
    "#df_sample = df.sample(1000)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61618, 26)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummies, and split X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum = pd.get_dummies(df, drop_first = True, columns = ['Type'])\n",
    "X = df_dum.drop(columns = ['price'])\n",
    "y = df_dum['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test, dev, val and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "First, we train (fit) a linear regression on the development (in this case the **training**) data, as it does not need validation (no hyperparameter needs to be optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('standardscaler', StandardScaler(copy=True, with_mean=0, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create pipeline (pipe_lr which will be used later, to compare Lasso and LR)\n",
    "pipe_lr = make_pipeline(PolynomialFeatures(include_bias=True, degree = 2), \n",
    "                        StandardScaler(with_mean = 0, with_std = True),\n",
    "                        LinearRegression())\n",
    "\n",
    "#Fit pipline to dev-data\n",
    "pipe_lr.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS (linear regression) estimations table\n",
    "\n",
    "Find a way to get the OLS estimates out here, in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.765</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.765</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   5022.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 27 Aug 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:33:52</td>     <th>  Log-Likelihood:    </th> <td>-7.7377e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 49294</td>      <th>  AIC:               </th>  <td>1.548e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 49262</td>      <th>  BIC:               </th>  <td>1.548e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    32</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>basementSize</th>                     <td> 8933.8327</td> <td>  244.980</td> <td>   36.468</td> <td> 0.000</td> <td> 8453.668</td> <td> 9413.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buildYear</th>                        <td>  765.8151</td> <td>   58.506</td> <td>   13.090</td> <td> 0.000</td> <td>  651.143</td> <td>  880.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rooms</th>                            <td>-1.998e+04</td> <td> 6756.066</td> <td>   -2.957</td> <td> 0.003</td> <td>-3.32e+04</td> <td>-6733.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>                             <td> 1.718e+04</td> <td>  190.006</td> <td>   90.435</td> <td> 0.000</td> <td> 1.68e+04</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grundskole</th>                       <td>-6.576e+04</td> <td> 4418.105</td> <td>  -14.883</td> <td> 0.000</td> <td>-7.44e+04</td> <td>-5.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gymnasiale uddannelser</th>           <td>  3.21e+05</td> <td> 1.56e+04</td> <td>   20.510</td> <td> 0.000</td> <td>  2.9e+05</td> <td> 3.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Erhvervsfaglige uddannelser</th>      <td>-7.329e+04</td> <td> 4248.630</td> <td>  -17.250</td> <td> 0.000</td> <td>-8.16e+04</td> <td> -6.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KVU</th>                              <td>-1.104e+05</td> <td> 1.47e+04</td> <td>   -7.494</td> <td> 0.000</td> <td>-1.39e+05</td> <td>-8.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MVU</th>                              <td>-8.622e+04</td> <td> 4236.494</td> <td>  -20.352</td> <td> 0.000</td> <td>-9.45e+04</td> <td>-7.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bacheloruddannelser</th>              <td> 2.032e+05</td> <td> 4.82e+04</td> <td>    4.214</td> <td> 0.000</td> <td> 1.09e+05</td> <td> 2.98e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> LVU</th>                             <td>-3.986e+04</td> <td> 7333.490</td> <td>   -5.435</td> <td> 0.000</td> <td>-5.42e+04</td> <td>-2.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kommunal_gennemsnitsinkomst_2017</th> <td>    6.8967</td> <td>    0.332</td> <td>   20.761</td> <td> 0.000</td> <td>    6.246</td> <td>    7.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Population_in_urban_development</th>  <td> 7963.5134</td> <td>  895.866</td> <td>    8.889</td> <td> 0.000</td> <td> 6207.604</td> <td> 9719.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_class_size</th>               <td>-1.141e+04</td> <td> 6964.493</td> <td>   -1.639</td> <td> 0.101</td> <td>-2.51e+04</td> <td> 2238.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lake_distance</th>                    <td> 1.431e+04</td> <td> 1405.252</td> <td>   10.180</td> <td> 0.000</td> <td> 1.16e+04</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>doctor_distance</th>                  <td>  1.43e+04</td> <td> 3263.341</td> <td>    4.382</td> <td> 0.000</td> <td> 7902.690</td> <td> 2.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>supermarket_distance</th>             <td>-3.271e+04</td> <td> 3308.217</td> <td>   -9.887</td> <td> 0.000</td> <td>-3.92e+04</td> <td>-2.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>school_distance</th>                  <td> 3.204e+04</td> <td> 4576.630</td> <td>    7.001</td> <td> 0.000</td> <td> 2.31e+04</td> <td>  4.1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daycare_distance</th>                 <td> 9880.5553</td> <td> 4946.344</td> <td>    1.998</td> <td> 0.046</td> <td>  185.662</td> <td> 1.96e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hospital_distance</th>                <td>-1.645e+04</td> <td>  990.150</td> <td>  -16.609</td> <td> 0.000</td> <td>-1.84e+04</td> <td>-1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>train_distance</th>                   <td>-5066.8931</td> <td>  694.042</td> <td>   -7.301</td> <td> 0.000</td> <td>-6427.225</td> <td>-3706.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pharmacy_distance</th>                <td>-2.057e+04</td> <td> 2546.416</td> <td>   -8.076</td> <td> 0.000</td> <td>-2.56e+04</td> <td>-1.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>library_distance</th>                 <td>-1.704e+04</td> <td> 2481.356</td> <td>   -6.868</td> <td> 0.000</td> <td>-2.19e+04</td> <td>-1.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junction_distance</th>                <td> 3268.9939</td> <td>  643.241</td> <td>    5.082</td> <td> 0.000</td> <td> 2008.235</td> <td> 4529.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Ejerlejlighed</th>               <td> 1.092e+06</td> <td> 6.21e+04</td> <td>   17.578</td> <td> 0.000</td> <td>  9.7e+05</td> <td> 1.21e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Fritidsgrund</th>                <td> 3.968e+06</td> <td> 1.41e+05</td> <td>   28.089</td> <td> 0.000</td> <td> 3.69e+06</td> <td> 4.24e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Fritidshus</th>                  <td> 1.989e+06</td> <td>  6.4e+04</td> <td>   31.070</td> <td> 0.000</td> <td> 1.86e+06</td> <td> 2.11e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Helårsgrund</th>                 <td> 3.755e+06</td> <td>  1.3e+05</td> <td>   28.787</td> <td> 0.000</td> <td>  3.5e+06</td> <td> 4.01e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Landejendom</th>                 <td> 1.723e+06</td> <td> 6.95e+04</td> <td>   24.804</td> <td> 0.000</td> <td> 1.59e+06</td> <td> 1.86e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Rækkehus</th>                    <td> 1.209e+06</td> <td>  6.7e+04</td> <td>   18.037</td> <td> 0.000</td> <td> 1.08e+06</td> <td> 1.34e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Villa</th>                       <td> 9.025e+05</td> <td> 6.05e+04</td> <td>   14.930</td> <td> 0.000</td> <td> 7.84e+05</td> <td> 1.02e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_Villalejlighed</th>              <td>   7.1e+05</td> <td>  1.2e+05</td> <td>    5.913</td> <td> 0.000</td> <td> 4.75e+05</td> <td> 9.45e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>67523.042</td> <th>  Durbin-Watson:     </th>   <td>   2.005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>82626152.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 7.331</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>203.034</td>  <th>  Cond. No.          </th>   <td>9.12e+06</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.12e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.765\n",
       "Model:                            OLS   Adj. R-squared:                  0.765\n",
       "Method:                 Least Squares   F-statistic:                     5022.\n",
       "Date:                Tue, 27 Aug 2019   Prob (F-statistic):               0.00\n",
       "Time:                        12:33:52   Log-Likelihood:            -7.7377e+05\n",
       "No. Observations:               49294   AIC:                         1.548e+06\n",
       "Df Residuals:                   49262   BIC:                         1.548e+06\n",
       "Df Model:                          32                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================\n",
       "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "basementSize                      8933.8327    244.980     36.468      0.000    8453.668    9413.997\n",
       "buildYear                          765.8151     58.506     13.090      0.000     651.143     880.488\n",
       "rooms                            -1.998e+04   6756.066     -2.957      0.003   -3.32e+04   -6733.690\n",
       "size                              1.718e+04    190.006     90.435      0.000    1.68e+04    1.76e+04\n",
       "Grundskole                       -6.576e+04   4418.105    -14.883      0.000   -7.44e+04   -5.71e+04\n",
       "Gymnasiale uddannelser             3.21e+05   1.56e+04     20.510      0.000     2.9e+05    3.52e+05\n",
       "Erhvervsfaglige uddannelser      -7.329e+04   4248.630    -17.250      0.000   -8.16e+04    -6.5e+04\n",
       "KVU                              -1.104e+05   1.47e+04     -7.494      0.000   -1.39e+05   -8.15e+04\n",
       "MVU                              -8.622e+04   4236.494    -20.352      0.000   -9.45e+04   -7.79e+04\n",
       "Bacheloruddannelser               2.032e+05   4.82e+04      4.214      0.000    1.09e+05    2.98e+05\n",
       " LVU                             -3.986e+04   7333.490     -5.435      0.000   -5.42e+04   -2.55e+04\n",
       "Kommunal_gennemsnitsinkomst_2017     6.8967      0.332     20.761      0.000       6.246       7.548\n",
       "Population_in_urban_development   7963.5134    895.866      8.889      0.000    6207.604    9719.422\n",
       "average_class_size               -1.141e+04   6964.493     -1.639      0.101   -2.51e+04    2238.285\n",
       "lake_distance                     1.431e+04   1405.252     10.180      0.000    1.16e+04    1.71e+04\n",
       "doctor_distance                    1.43e+04   3263.341      4.382      0.000    7902.690    2.07e+04\n",
       "supermarket_distance             -3.271e+04   3308.217     -9.887      0.000   -3.92e+04   -2.62e+04\n",
       "school_distance                   3.204e+04   4576.630      7.001      0.000    2.31e+04     4.1e+04\n",
       "daycare_distance                  9880.5553   4946.344      1.998      0.046     185.662    1.96e+04\n",
       "hospital_distance                -1.645e+04    990.150    -16.609      0.000   -1.84e+04   -1.45e+04\n",
       "train_distance                   -5066.8931    694.042     -7.301      0.000   -6427.225   -3706.562\n",
       "pharmacy_distance                -2.057e+04   2546.416     -8.076      0.000   -2.56e+04   -1.56e+04\n",
       "library_distance                 -1.704e+04   2481.356     -6.868      0.000   -2.19e+04   -1.22e+04\n",
       "junction_distance                 3268.9939    643.241      5.082      0.000    2008.235    4529.753\n",
       "Type_Ejerlejlighed                1.092e+06   6.21e+04     17.578      0.000     9.7e+05    1.21e+06\n",
       "Type_Fritidsgrund                 3.968e+06   1.41e+05     28.089      0.000    3.69e+06    4.24e+06\n",
       "Type_Fritidshus                   1.989e+06    6.4e+04     31.070      0.000    1.86e+06    2.11e+06\n",
       "Type_Helårsgrund                  3.755e+06    1.3e+05     28.787      0.000     3.5e+06    4.01e+06\n",
       "Type_Landejendom                  1.723e+06   6.95e+04     24.804      0.000    1.59e+06    1.86e+06\n",
       "Type_Rækkehus                     1.209e+06    6.7e+04     18.037      0.000    1.08e+06    1.34e+06\n",
       "Type_Villa                        9.025e+05   6.05e+04     14.930      0.000    7.84e+05    1.02e+06\n",
       "Type_Villalejlighed                 7.1e+05    1.2e+05      5.913      0.000    4.75e+05    9.45e+05\n",
       "==============================================================================\n",
       "Omnibus:                    67523.042   Durbin-Watson:                   2.005\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         82626152.628\n",
       "Skew:                           7.331   Prob(JB):                         0.00\n",
       "Kurtosis:                     203.034   Cond. No.                     9.12e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.12e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS_est = sm.OLS(y_dev, X_dev).fit()\n",
    "\n",
    "OLS_est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Lasso Regression (K-fold CV)\n",
    "\n",
    "Now we want to examine whether the a Lasso regression is more appropriate, and seeks to optimize the hyperparameter.\n",
    "We will train for an optimized hyperparameter on the validation set, to avoid data leakage and use k-fold crossvalidation to make sure that we have not split our dataset in a lucky or unlucky place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [2:16:49<00:00, 357.11s/it]  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Split data into 5 folds\n",
    "kfolds = KFold(n_splits=5)\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "#Create Lambda values\n",
    "lambdas = np.logspace(-1, 7, 12)\n",
    "# outer loop: lambdas\n",
    "mseCV = []\n",
    "\n",
    "for lambda_ in tqdm.tqdm(lambdas):    \n",
    "    # inner loop: folds\n",
    "    mseCV_ = []\n",
    "\n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=3, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     Lasso(alpha=lambda_, random_state=1))            \n",
    "        X_train, y_train = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        pipe_lassoCV.fit(X_train, y_train)        \n",
    "        mseCV_.append(mse(pipe_lassoCV.predict(X_val), y_val))\n",
    "\n",
    "        \n",
    "    # store result    \n",
    "    mseCV.append(mseCV_) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambda_mseCV_lasso = pd.DataFrame(mseCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE of the K-fold Crossvalidation - Lasso\n",
    "\n",
    "Lambda as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.000000e-01</th>\n",
       "      <td>2.831965e+12</td>\n",
       "      <td>1.260413e+13</td>\n",
       "      <td>1.768074e+12</td>\n",
       "      <td>2.679605e+12</td>\n",
       "      <td>2.337296e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.336699e-01</th>\n",
       "      <td>2.827059e+12</td>\n",
       "      <td>1.261005e+13</td>\n",
       "      <td>1.767513e+12</td>\n",
       "      <td>2.679546e+12</td>\n",
       "      <td>2.336539e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.848036e+00</th>\n",
       "      <td>2.802419e+12</td>\n",
       "      <td>1.263911e+13</td>\n",
       "      <td>1.764603e+12</td>\n",
       "      <td>2.678959e+12</td>\n",
       "      <td>2.330414e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.519911e+01</th>\n",
       "      <td>2.700116e+12</td>\n",
       "      <td>1.277790e+13</td>\n",
       "      <td>1.748691e+12</td>\n",
       "      <td>2.672321e+12</td>\n",
       "      <td>2.307638e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.111308e+01</th>\n",
       "      <td>2.407817e+12</td>\n",
       "      <td>1.342065e+13</td>\n",
       "      <td>1.675047e+12</td>\n",
       "      <td>2.560026e+12</td>\n",
       "      <td>2.193921e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.328761e+02</th>\n",
       "      <td>2.249848e+12</td>\n",
       "      <td>1.831944e+13</td>\n",
       "      <td>1.572803e+12</td>\n",
       "      <td>2.287128e+12</td>\n",
       "      <td>1.845917e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.310130e+03</th>\n",
       "      <td>2.246939e+12</td>\n",
       "      <td>1.010932e+13</td>\n",
       "      <td>1.514323e+12</td>\n",
       "      <td>1.795144e+12</td>\n",
       "      <td>1.662090e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.232847e+04</th>\n",
       "      <td>2.330799e+12</td>\n",
       "      <td>1.590631e+12</td>\n",
       "      <td>1.599433e+12</td>\n",
       "      <td>1.667488e+12</td>\n",
       "      <td>1.635345e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.579332e+04</th>\n",
       "      <td>2.478147e+12</td>\n",
       "      <td>1.679357e+12</td>\n",
       "      <td>1.831601e+12</td>\n",
       "      <td>1.751166e+12</td>\n",
       "      <td>1.817800e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.511192e+05</th>\n",
       "      <td>2.915373e+12</td>\n",
       "      <td>2.031745e+12</td>\n",
       "      <td>2.203023e+12</td>\n",
       "      <td>2.271948e+12</td>\n",
       "      <td>1.950150e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.873817e+06</th>\n",
       "      <td>6.120084e+12</td>\n",
       "      <td>5.151996e+12</td>\n",
       "      <td>5.432800e+12</td>\n",
       "      <td>5.705100e+12</td>\n",
       "      <td>4.782396e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e+07</th>\n",
       "      <td>6.120084e+12</td>\n",
       "      <td>5.151996e+12</td>\n",
       "      <td>5.432800e+12</td>\n",
       "      <td>5.705100e+12</td>\n",
       "      <td>4.782396e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0             1             2             3  \\\n",
       "1.000000e-01  2.831965e+12  1.260413e+13  1.768074e+12  2.679605e+12   \n",
       "5.336699e-01  2.827059e+12  1.261005e+13  1.767513e+12  2.679546e+12   \n",
       "2.848036e+00  2.802419e+12  1.263911e+13  1.764603e+12  2.678959e+12   \n",
       "1.519911e+01  2.700116e+12  1.277790e+13  1.748691e+12  2.672321e+12   \n",
       "8.111308e+01  2.407817e+12  1.342065e+13  1.675047e+12  2.560026e+12   \n",
       "4.328761e+02  2.249848e+12  1.831944e+13  1.572803e+12  2.287128e+12   \n",
       "2.310130e+03  2.246939e+12  1.010932e+13  1.514323e+12  1.795144e+12   \n",
       "1.232847e+04  2.330799e+12  1.590631e+12  1.599433e+12  1.667488e+12   \n",
       "6.579332e+04  2.478147e+12  1.679357e+12  1.831601e+12  1.751166e+12   \n",
       "3.511192e+05  2.915373e+12  2.031745e+12  2.203023e+12  2.271948e+12   \n",
       "1.873817e+06  6.120084e+12  5.151996e+12  5.432800e+12  5.705100e+12   \n",
       "1.000000e+07  6.120084e+12  5.151996e+12  5.432800e+12  5.705100e+12   \n",
       "\n",
       "                         4  \n",
       "1.000000e-01  2.337296e+12  \n",
       "5.336699e-01  2.336539e+12  \n",
       "2.848036e+00  2.330414e+12  \n",
       "1.519911e+01  2.307638e+12  \n",
       "8.111308e+01  2.193921e+12  \n",
       "4.328761e+02  1.845917e+12  \n",
       "2.310130e+03  1.662090e+12  \n",
       "1.232847e+04  1.635345e+12  \n",
       "6.579332e+04  1.817800e+12  \n",
       "3.511192e+05  1.950150e+12  \n",
       "1.873817e+06  4.782396e+12  \n",
       "1.000000e+07  4.782396e+12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_mseCV_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean MSE of K-fold CV - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean of the folds\n",
    "mse_mean_lasso = lambda_mseCV_lasso.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Average MSE over Lambda - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0.5,'MSE'), Text(0.5,0,'Lambda')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mean square errors\n",
    "COL = ['Average MSE']\n",
    "mse_mean_lasso.columns = COL\n",
    "\n",
    "#Both axis are logarythmical \n",
    "ax = mse_mean_lasso.plot(logx = True, logy = True)\n",
    "ax.set(xlabel = 'Lambda', ylabel = 'MSE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal hyperparameter for Lasso\n",
    "\n",
    "Where was the mean mse smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12328.467394    1.764739e+12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_mean_lasso.nsmallest(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Ridge Regression (K-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [40:56<00:00, 206.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#Split data into 5 folds\n",
    "kfolds = KFold(n_splits=5)\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "#Create Lambda values\n",
    "lambdas = np.logspace(-1, 7, 12)\n",
    "# outer loop: lambdas\n",
    "mseCV = []\n",
    "\n",
    "for lambda_ in tqdm.tqdm(lambdas):    \n",
    "    # inner loop: folds\n",
    "    mseCV_ = []\n",
    "\n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_ridgeCV = make_pipeline(PolynomialFeatures(degree=3, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     Ridge(alpha=lambda_, random_state=1))            \n",
    "        X_train, y_train = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        pipe_ridgeCV.fit(X_train, y_train)        \n",
    "        mseCV_.append(mse(pipe_ridgeCV.predict(X_val), y_val))\n",
    "\n",
    "        \n",
    "    # store result    \n",
    "    mseCV.append(mseCV_) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambda_mseCV_ridge = pd.DataFrame(mseCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE of the K-fold Crossvalidation - Ridge\n",
    "\n",
    "Lambda as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.000000e-01</th>\n",
       "      <td>5.567202e+12</td>\n",
       "      <td>3.186564e+13</td>\n",
       "      <td>3.466011e+12</td>\n",
       "      <td>4.571067e+12</td>\n",
       "      <td>5.485509e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.336699e-01</th>\n",
       "      <td>4.416797e+12</td>\n",
       "      <td>2.559059e+13</td>\n",
       "      <td>2.595326e+12</td>\n",
       "      <td>3.349633e+12</td>\n",
       "      <td>3.568724e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.848036e+00</th>\n",
       "      <td>4.135396e+12</td>\n",
       "      <td>2.291449e+13</td>\n",
       "      <td>1.999430e+12</td>\n",
       "      <td>2.794764e+12</td>\n",
       "      <td>2.645210e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.519911e+01</th>\n",
       "      <td>3.019644e+12</td>\n",
       "      <td>2.225017e+13</td>\n",
       "      <td>1.654110e+12</td>\n",
       "      <td>2.451778e+12</td>\n",
       "      <td>2.110118e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.111308e+01</th>\n",
       "      <td>2.374617e+12</td>\n",
       "      <td>2.037564e+13</td>\n",
       "      <td>1.486566e+12</td>\n",
       "      <td>2.040216e+12</td>\n",
       "      <td>1.853832e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.328761e+02</th>\n",
       "      <td>2.255346e+12</td>\n",
       "      <td>1.657115e+13</td>\n",
       "      <td>1.458870e+12</td>\n",
       "      <td>1.751136e+12</td>\n",
       "      <td>1.696521e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.310130e+03</th>\n",
       "      <td>2.238653e+12</td>\n",
       "      <td>8.593573e+12</td>\n",
       "      <td>1.533356e+12</td>\n",
       "      <td>1.636932e+12</td>\n",
       "      <td>1.588441e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.232847e+04</th>\n",
       "      <td>2.281382e+12</td>\n",
       "      <td>2.651279e+12</td>\n",
       "      <td>1.637992e+12</td>\n",
       "      <td>1.601040e+12</td>\n",
       "      <td>1.545406e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.579332e+04</th>\n",
       "      <td>2.377840e+12</td>\n",
       "      <td>1.581054e+12</td>\n",
       "      <td>1.768986e+12</td>\n",
       "      <td>1.648998e+12</td>\n",
       "      <td>1.563863e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.511192e+05</th>\n",
       "      <td>2.584702e+12</td>\n",
       "      <td>1.770691e+12</td>\n",
       "      <td>2.050472e+12</td>\n",
       "      <td>1.844861e+12</td>\n",
       "      <td>1.674892e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.873817e+06</th>\n",
       "      <td>3.015743e+12</td>\n",
       "      <td>2.170420e+12</td>\n",
       "      <td>2.521086e+12</td>\n",
       "      <td>2.318152e+12</td>\n",
       "      <td>1.987283e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e+07</th>\n",
       "      <td>3.858969e+12</td>\n",
       "      <td>2.966901e+12</td>\n",
       "      <td>3.248230e+12</td>\n",
       "      <td>3.281356e+12</td>\n",
       "      <td>2.686429e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0             1             2             3  \\\n",
       "1.000000e-01  5.567202e+12  3.186564e+13  3.466011e+12  4.571067e+12   \n",
       "5.336699e-01  4.416797e+12  2.559059e+13  2.595326e+12  3.349633e+12   \n",
       "2.848036e+00  4.135396e+12  2.291449e+13  1.999430e+12  2.794764e+12   \n",
       "1.519911e+01  3.019644e+12  2.225017e+13  1.654110e+12  2.451778e+12   \n",
       "8.111308e+01  2.374617e+12  2.037564e+13  1.486566e+12  2.040216e+12   \n",
       "4.328761e+02  2.255346e+12  1.657115e+13  1.458870e+12  1.751136e+12   \n",
       "2.310130e+03  2.238653e+12  8.593573e+12  1.533356e+12  1.636932e+12   \n",
       "1.232847e+04  2.281382e+12  2.651279e+12  1.637992e+12  1.601040e+12   \n",
       "6.579332e+04  2.377840e+12  1.581054e+12  1.768986e+12  1.648998e+12   \n",
       "3.511192e+05  2.584702e+12  1.770691e+12  2.050472e+12  1.844861e+12   \n",
       "1.873817e+06  3.015743e+12  2.170420e+12  2.521086e+12  2.318152e+12   \n",
       "1.000000e+07  3.858969e+12  2.966901e+12  3.248230e+12  3.281356e+12   \n",
       "\n",
       "                         4  \n",
       "1.000000e-01  5.485509e+12  \n",
       "5.336699e-01  3.568724e+12  \n",
       "2.848036e+00  2.645210e+12  \n",
       "1.519911e+01  2.110118e+12  \n",
       "8.111308e+01  1.853832e+12  \n",
       "4.328761e+02  1.696521e+12  \n",
       "2.310130e+03  1.588441e+12  \n",
       "1.232847e+04  1.545406e+12  \n",
       "6.579332e+04  1.563863e+12  \n",
       "3.511192e+05  1.674892e+12  \n",
       "1.873817e+06  1.987283e+12  \n",
       "1.000000e+07  2.686429e+12  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_mseCV_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean MSE of K-fold CV - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean of the folds\n",
    "mse_mean_ridge = lambda_mseCV_ridge.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Average MSE over Lambda - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0.5,'MSE'), Text(0.5,0,'Lambda')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mean square errors\n",
    "COL = ['Average MSE']\n",
    "mse_mean_ridge.columns = COL\n",
    "\n",
    "#Both axis are logarythmical \n",
    "ax = mse_mean_ridge.plot(logx = True, logy = True)\n",
    "ax.set(xlabel = 'Lambda', ylabel = 'MSE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal hyperparameter for Ridge\n",
    "\n",
    "Where was the mean mse smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65793.322466    1.788148e+12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_mean_ridge.nsmallest(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Elastic Net Regression (K-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [33:00<2:44:35, 987.51s/it]"
     ]
    }
   ],
   "source": [
    "#Split data into 5 folds\n",
    "kfolds = KFold(n_splits=5)\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "#Create Lambda values\n",
    "lambdas = np.logspace(-1, 7, 12)\n",
    "# outer loop: lambdas\n",
    "mseCV = []\n",
    "\n",
    "for lambda_ in tqdm.tqdm(lambdas):    \n",
    "    # inner loop: folds\n",
    "    mseCV_ = []\n",
    "\n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_elasticCV = make_pipeline(PolynomialFeatures(degree=3, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     ElasticNet(alpha=lambda_, random_state=1))            \n",
    "        X_train, y_train = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "        pipe_elasticCV.fit(X_train, y_train)        \n",
    "        mseCV_.append(mse(pipe_elasticCV.predict(X_val), y_val))\n",
    "\n",
    "        \n",
    "    # store result    \n",
    "    mseCV.append(mseCV_) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambda_mseCV_elastic = pd.DataFrame(mseCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE of the K-fold Crossvalidation - Elastic\n",
    "Lambda as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_mseCV_elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean MSE of K-fold CV - Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean of the folds\n",
    "mse_mean_elastic = lambda_mseCV_elastic.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Average MSE over Lambda - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot mean square errors\n",
    "COL = ['Average MSE']\n",
    "mse_mean_elastic.columns = COL\n",
    "\n",
    "#Both axis are logarythmical \n",
    "ax = mse_mean_elastic.plot(logx = True, logy = True)\n",
    "ax.set(xlabel = 'Lambda', ylabel = 'MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal hyperparameter for Ridge\n",
    "\n",
    "Where was the mean mse smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_mean_elastic.nsmallest(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Lasso, Ridge, Elastic Net and Linear Regression\n",
    "\n",
    "Is done after the optimized hyperparameters is found (after training on validation data)\n",
    "This comparison is done on the **test data!** and is thus the final step in training and selecting our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal lambda is inserted into the Lasso-model\n",
    "optimal_lambda_lasso = lambda_mseCV_lasso.mean(axis=1).nsmallest(1)\n",
    "\n",
    "# retrain/re-estimate model using optimal hyperparameters\n",
    "pipe_lassoCV = make_pipeline(PolynomialFeatures(degree = 3, include_bias=False), \n",
    "                             StandardScaler(),\n",
    "                             Lasso(alpha=optimal_lambda_lasso.index[0], random_state=1))\n",
    "pipe_lassoCV.fit(X_dev,y_dev)\n",
    "\n",
    "#Optimal lambda for ridge model: \n",
    "optimal_lambda_ridge = lambda_mseCV_ridge.mean(axis=1).nsmallest(1)\n",
    "\n",
    "# retrain/re-estimate model using optimal hyperparameters\n",
    "pipe_ridgeCV = make_pipeline(PolynomialFeatures(degree = 3, include_bias=False), \n",
    "                             StandardScaler(),\n",
    "                             Lasso(alpha=optimal_lambda_ridge.index[0], random_state=1))\n",
    "pipe_ridgeCV.fit(X_dev,y_dev)\n",
    "\n",
    "#Optimal lambda for elastic net model: \n",
    "optimal_lambda_elastic = lambda_mseCV_elastic.mean(axis=1).nsmallest(1)\n",
    "\n",
    "# retrain/re-estimate model using optimal hyperparameters\n",
    "pipe_elasticCV = make_pipeline(PolynomialFeatures(degree = 3, include_bias=False), \n",
    "                             StandardScaler(),\n",
    "                             ElasticNet(alpha=optimal_lambda_elastic.index[0], random_state=1))\n",
    "pipe_elasticCV.fit(X_dev,y_dev)\n",
    "\n",
    "# compare performance by mse\n",
    "models = {'Lasso CV': pipe_lassoCV, 'Ridge CV': pipe_ridgeCV, 'ElasticNet CV': pipe_elasticCV,\n",
    "          'LinReg': pipe_lr}\n",
    "for name, model in models.items():\n",
    "    score_mse = mse(model.predict(X_test),y_test)\n",
    "    score_mae = mae(model.predict(X_test),y_test)\n",
    "    score_rmse = sqrt(mse(model.predict(X_test),y_test))\n",
    "    \n",
    "    print(\"MSE: \" + name, round(score_mse, 2))\n",
    "    print(\"RMSE: \" + name, round(score_rmse, 2))\n",
    "    print(\"MAE: \" + name, round(score_mae, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subconclusion\n",
    "\n",
    "The model is too complex and very unable to predict out-of-sample data. \n",
    "Though the Lasso is a great imporvement to the simple linear regression, it still produces error in the realm of trillions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Table\n",
    "\n",
    "We calculate the Mean Absolute Error, Mean Squared Error and Root Mean Squard Errors of the differnet models: OLS (Linear Regression), Lasso, Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
